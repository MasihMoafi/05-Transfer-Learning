{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825a8952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the pretrained VGG19 model\n",
    "vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n",
    "vgg.trainable = False\n",
    "\n",
    "# Load and preprocess the content and style images\n",
    "content_path = \"C:/Users/Josep/OneDrive/Desktop/1.jpg\"\n",
    "style_path = \"C:/Users/Josep/OneDrive/Desktop/2.jpg\"\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_image(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, (256, 256))\n",
    "    image = image[tf.newaxis, :]\n",
    "    return image\n",
    "\n",
    "content_image = load_and_preprocess_image(content_path)\n",
    "style_image = load_and_preprocess_image(style_path)\n",
    "\n",
    "# Define the loss functions and weights\n",
    "content_weight = 1  # Weight for content loss\n",
    "style_weight = 10  # Weight for style loss\n",
    "\n",
    "def get_feature_representations(model, content_image, style_image):\n",
    "    content_outputs = model(content_image)\n",
    "    style_outputs = model(style_image)\n",
    "    return content_outputs, style_outputs\n",
    "\n",
    "def gram_matrix(tensor):\n",
    "    channels = int(tensor.shape[-1])\n",
    "    a = tf.reshape(tensor, [-1, channels])\n",
    "    n = tf.shape(a)[0]\n",
    "    gram = tf.matmul(a, a, transpose_a=True)\n",
    "    return gram / tf.cast(n, tf.float32)\n",
    "\n",
    "def compute_loss(model, generated_image, content_outputs, style_outputs, content_weight, style_weight):\n",
    "    generated_content_outputs = model(generated_image)\n",
    "    content_loss = tf.reduce_mean(tf.square(generated_content_outputs - content_outputs))\n",
    "\n",
    "    style_loss = 0\n",
    "    for gen_output, style_output in zip(generated_content_outputs, style_outputs):\n",
    "        gen_gram = gram_matrix(gen_output)\n",
    "        style_gram = gram_matrix(style_output)\n",
    "        style_loss += tf.reduce_mean(tf.square(gen_gram - style_gram))\n",
    "\n",
    "    content_loss *= content_weight\n",
    "    style_loss *= style_weight\n",
    "    total_loss = content_loss + style_loss\n",
    "    return total_loss, content_loss, style_loss\n",
    "\n",
    "def compute_gradients(config):\n",
    "    with tf.GradientTape() as tape:\n",
    "        all_loss = compute_loss(**config)\n",
    "    total_loss = all_loss[0]\n",
    "    return tape.gradient(total_loss, config['generated_image']), all_loss\n",
    "\n",
    "def run_style_transfer(content_path, style_path, num_iterations=200, content_weight=1e3, style_weight=1e-2):\n",
    "    content_image = load_and_preprocess_image(content_path)\n",
    "    style_image = load_and_preprocess_image(style_path)\n",
    "\n",
    "    content_outputs, style_outputs = get_feature_representations(vgg, content_image, style_image)\n",
    "\n",
    "    generated_image = tf.Variable(content_image, dtype=tf.float32)\n",
    "\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "    config = {\n",
    "        'model': vgg,\n",
    "        'generated_image': generated_image,\n",
    "        'content_outputs': content_outputs,\n",
    "        'style_outputs': style_outputs,\n",
    "        'content_weight': content_weight,\n",
    "        'style_weight': style_weight\n",
    "    }\n",
    "\n",
    "    best_loss, best_image = float('inf'), None\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        gradients, all_loss = compute_gradients(config)\n",
    "        total_loss, content_loss, style_loss = all_loss\n",
    "        optimizer.apply_gradients([(gradients, generated_image)])\n",
    "\n",
    "        if total_loss < best_loss:\n",
    "            best_loss = total_loss\n",
    "            best_image = generated_image.numpy()\n",
    "\n",
    "        if (i + 1) % 20 == 0:\n",
    "            print(f\"Iteration: {i+1}/{num_iterations}, Total loss: {total_loss:.4f}, \"\n",
    "                  f\"Content loss: {content_loss:.4f}, Style loss: {style_loss:.4f}\")\n",
    "\n",
    "    return best_image\n",
    "\n",
    "# Run style transfer\n",
    "output_image = run_style_transfer(content_path, style_path, num_iterations=200, content_weight=1e3, style_weight=1e-2)\n",
    "\n",
    "# Convert the output image to a PIL image\n",
    "output_image = tf.clip_by_value(output_image, 0.0, 1.0)\n",
    "output_image = tf.squeeze(output_image, axis=0)\n",
    "output_image = tf.keras.preprocessing.image.array_to_img(output_image)\n",
    "\n",
    "# Save the generated image\n",
    "output_image.save(\"C:/Users/Josep/OneDrive/Desktop/3.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f953d2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the generated image\n",
    "generated_image = Image.open(\"C:/Users/Josep/OneDrive/Desktop/3.jpg\")\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(generated_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcbcd3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf210",
   "language": "python",
   "name": "tf210"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
